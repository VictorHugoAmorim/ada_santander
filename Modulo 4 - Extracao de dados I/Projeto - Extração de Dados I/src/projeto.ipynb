{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enunciado\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grupo: Arthur Sorrentino, Danielle Gameiro, Erick Sasaki, Guilherme Quadros, Victor Amorim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Projeto - Extração de Dados I\n",
    "------------------------------\n",
    "## Sistema de Monitoramento de Avanços no Campo da Genômica  \n",
    "\n",
    "## Contexto:  \n",
    "O grupo trabalha no time de engenharia de dados na HealthGen, uma empresa especializada em genômica e pesquisa de medicina personalizada. A genômica é o estudo do conjunto completo de genes de um organismo, desempenha um papel fundamental na medicina personalizada e na pesquisa biomédica. Permite a análise do DNA para identificar variantes genéticas e mutações associadas a doenças e facilita a personalização de tratamentos com base nas características genéticas individuais dos pacientes.\n",
    "\n",
    "A empresa precisa se manter atualizada sobre os avanços mais recentes na genômica, identificar oportunidades para pesquisa e desenvolvimento de tratamentos personalizados e acompanhar as tendências em genômica que podem influenciar estratégias de pesquisa e desenvolvimento. Pensando nisso, o time de dados apresentou uma proposta de desenvolvimento de um sistema que coleta, analisa e apresenta as últimas notícias relacionadas à genômica e à medicina personalizada, e também estuda o avanço do campo nos últimos anos.\n",
    "\n",
    "O time de engenharia de dados tem como objetivo desenvolver e garantir um pipeline de dados confiável e estável. As principais atividades são:\n",
    "\n",
    "### 1. Consumo de dados com a News API:  \n",
    "Implementar um mecanismo para consumir dados de notícias de fontes confiáveis e especializadas em genômica e medicina personalizada, a partir da News API:  \n",
    "https://newsapi.org/\n",
    "\n",
    "### 2. Definir Critérios de Relevância:  \n",
    "Desenvolver critérios precisos de relevância para filtrar as notícias. Por exemplo, o time pode se concentrar em notícias que mencionem avanços em sequenciamento de DNA, terapias genéticas personalizadas ou descobertas relacionadas a doenças genéticas específicas.\n",
    "\n",
    "### 3. Cargas em Batches:  \n",
    "Armazenar as notícias relevantes em um formato estruturado e facilmente acessível para consultas e análises posteriores. Essa carga deve acontecer 1 vez por hora. Se as notícias extraídas já tiverem sidos armazenadas na carga anterior, o processo deve ignorar e não armazenar as notícias novamente, os dados carregados não podem ficar duplicados.  \n",
    "![Alt text](image.png)\n",
    "\n",
    "### 4. Dados transformados para consulta do público final  \n",
    "A partir dos dados carregados, aplicar as seguintes transformações e armazenar o resultado final para a consulta do público final:  \n",
    "\n",
    "4.1 - Quantidade de notícias por ano, mês e dia de publicação;  \n",
    "\n",
    "4.2 - Quantidade de notícias por fonte e autor;  \n",
    "\n",
    "4.3 - Quantidade de aparições de 3 palavras chaves por ano, mês e dia de publicação (as 3 palavras chaves serão as mesmas usadas para fazer os filtros de relevância do item 2 (2. Definir Critérios de Relevância)).  \n",
    "\n",
    "Atualizar os dados transformados 1 vez por dia.  \n",
    "\n",
    "![Alt text](image-1.png)\n",
    "\n",
    "----------------------------------------\n",
    "\n",
    "Além das atividades principais, existe a necessidade de busca de dados por eventos em tempo real quando é necessário, para isso foi desenhado duas opções:\n",
    "\n",
    "### Opção 1 - Apache Kafka e Spark Streaming:  \n",
    "\n",
    "Preparar um pipeline com Apache Kafka e Spark Streaming para receber os dados do Produtor Kafka representado por um evento manual e consumir os dados com o Spark Streaming armazenando os resultados temporariamente. Em um processo paralelo, verificar os resultados armazenados temporiamente e armazenar no mesmo destino do item 3 (3. Cargas em Batches) aqueles resultados que ainda não foram armazenados no destino (os dados carregados não podem ficar duplicados). E por fim, eliminar os dados temporários após a verificação e a eventual carga.\n",
    "\n",
    "![Alt text](image-2.png)\n",
    "\n",
    "### Opção 2 - Webhooks com notificações por eventos:  \n",
    "Configurar um webhook para adquirir as últimas notícias a partir de um evento representado por uma requisição POST e fazer a chamada da API e por fim armazenar os resultados temporariamente. Em um processo paralelo, verificar os resultados armazenados temporiamente e armazenar no mesmo destino do item 3 (3. Cargas em Batches) aqueles resultados que ainda não foram armazenados no destino (os dados carregados não podem ficar duplicados). E por fim, eliminar os dados temporários após a verificação e a eventual carga.\n",
    "\n",
    "![Alt text](image-3.png)\n",
    "\n",
    "Atividades que precisam ser realizadas pelo grupo definido em aula.  \n",
    "\n",
    "O grupo precisa construir o pipeline de dados seguindo os requisitos das atividades principais e escolher entre a Opção 1 e Opção 2 para desenvolvimento.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resolução"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Bibliotecas\n",
    "Para instalar as bibliotecas necessárias do projeto:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in c:\\users\\danie\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (2.31.0)\n",
      "Requirement already satisfied: newsapi-python in c:\\users\\danie\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (0.2.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\danie\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\danie\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests) (2023.7.22)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\danie\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests) (3.2.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\danie\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests) (2.0.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.1.3; however, version 23.2.1 is available.\n",
      "You should consider upgrading via the 'c:\\Users\\Danie\\AppData\\Local\\Programs\\Python\\Python39\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "pip install requests newsapi-python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para importas as bibliotecas e definir as variáveis necessárias:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from newsapi import NewsApiClient\n",
    "import requests\n",
    "import time\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "API_KEY = '9a77398581d74beebbd29dbebd159a53'\n",
    "PALAVRAS_CHAVES_GERAIS = '(genômica OR genômico) AND (terapia OR sequenciamento OR doença)'\n",
    "PALAVRAS_CHAVES_ESPECIFICAS = ['terapia', 'sequenciamento', 'doença']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Definições de Funções"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abaixo está localizado todas as definições de funções que será usado no projeto:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Consumo de dados com a News API -------------------------------------------------------------------------------------------------\n",
    "\n",
    "## 1 Usando Biblioteca NewsAPI\n",
    "def fazer_a_request_1( API_KEY:str='9a77398581d74beebbd29dbebd159a53' , PALAVRAS_CHAVES:str='(genômica OR genômico) AND (terapia OR sequenciamento OR doença)' ):\n",
    "    # A função realiza o request com API_KEY e PALAVRAS_CHAVES declaradas e é retornado um json\n",
    "    newsapi = NewsApiClient(api_key=API_KEY)\n",
    "    response_lib = newsapi.get_everything(q=PALAVRAS_CHAVES,\n",
    "                                        language='pt',\n",
    "                                        sort_by='publishedAt'\n",
    "    )\n",
    "    return response_lib\n",
    "\n",
    "## 2 Usando requests\n",
    "def fazer_a_request_2( API_KEY:str='9a77398581d74beebbd29dbebd159a53' , PALAVRAS_CHAVES:str='(genômica OR genômico) AND (terapia OR sequenciamento OR doença)' ):\n",
    "    # A função realiza o request com API_KEY e PALAVRAS_CHAVES declaradas e é retornado um json\n",
    "    url = f'https://newsapi.org/v2/everything?q={PALAVRAS_CHAVES}&language=pt&sortBy=publishedAt&apiKey={API_KEY}'\n",
    "    response_requests = requests.get(url).json()\n",
    "    return response_requests\n",
    "\n",
    "\n",
    "\n",
    "# 2. Definir Critérios de Relevância -------------------------------------------------------------------------------------------------\n",
    "\n",
    "def tratar_dados(json_de_noticias) -> pd.DataFrame:\n",
    "    # Transformar arquivo JSON em dataframe\n",
    "    df = pd.json_normalize(json_de_noticias['articles'])\n",
    "\n",
    "    # Tratar dados da coluna 'publishedAt'\n",
    "    df['publishedAt'] = pd.to_datetime(df['publishedAt']).dt.tz_localize(None)\n",
    "    df['publishedAt'] = df['publishedAt'].astype('datetime64[ms]')\n",
    "\n",
    "    # Tratar dados sem informação\n",
    "    df.fillna(\"desconhecido\", inplace=True)\n",
    "\n",
    "    # Remover noticias sem informações nas colunas: 'description', 'content' e 'source.name'\n",
    "    df = df[~df['description'].str.contains('desconhecido', case=False)]\n",
    "    df = df[~df['content'].str.contains('desconhecido', case=False)]\n",
    "    df = df[~df['source.name'].str.contains('desconhecido', case=False)]\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "# 3. Cargas em Batches: ---------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "def armazenar_noticias(df) -> None:\n",
    "    # Verifica se já existe um arquivo com os dados\n",
    "    if os.path.isfile('noticias.csv'):\n",
    "        # Lê o arquivo existente\n",
    "        df_existente = pd.read_csv('noticias.csv', index_col=0)\n",
    "\n",
    "        # Verifica se a coluna 'title' está presente em ambos os DataFrames\n",
    "        if 'title' in df.columns and 'title' in df_existente.columns:\n",
    "            # Identifica as notícias repetidas\n",
    "            df_repetidas = df[df['title'].isin(df_existente['title'])]\n",
    "\n",
    "            # Exclui as notícias repetidas do DataFrame de entrada\n",
    "            df = df[~df['title'].isin(df_existente['title'])]\n",
    "\n",
    "            # Concatena o DataFrame existente com as novas notícias\n",
    "            df_final = pd.concat([df_existente, df])\n",
    "\n",
    "            # Grava o dataframe resultante em um arquivo CSV\n",
    "            df_final.to_csv('noticias.csv', index=False)\n",
    "    else:\n",
    "        # Se o arquivo não existir, salva o DataFrame diretamente em 'noticias.csv'\n",
    "        df.to_csv('noticias.csv', index=False)\n",
    "\n",
    "    return None\n",
    "\n",
    "def carrega_armazenamento():\n",
    "    df = pd.read_csv('noticias.csv')\n",
    "    return df \n",
    "\n",
    "\n",
    "\n",
    "# 4. Dados transformados para consulta do público final ------------------------------------------------------------------------------\n",
    "\n",
    "def qtd_noticia_ano_mes_dia(df_inteiro): \n",
    "    # Calcula a quantidade de notícias por ano, mês/ano e dia/mês/ano\n",
    "    df_inteiro['ano'] = df_inteiro['publishedAt'].dt.year\n",
    "    df_inteiro['mes_ano'] = df_inteiro['publishedAt'].dt.to_period('M')\n",
    "    df_inteiro['dia_mes_ano'] = df_inteiro['publishedAt'].dt.to_period('D')\n",
    "    \n",
    "    qtd_por_ano = df_inteiro['ano'].value_counts().sort_index().reset_index()\n",
    "    qtd_por_ano.columns = ['ano', 'quantidade']\n",
    "\n",
    "    qtd_por_mes = df_inteiro['mes_ano'].value_counts().sort_index().reset_index()\n",
    "    qtd_por_mes.columns = ['mes_ano', 'quantidade']\n",
    "\n",
    "    qtd_por_dia = df_inteiro['dia_mes_ano'].value_counts().sort_index().reset_index()\n",
    "    qtd_por_dia.columns = ['dia_mes_ano', 'quantidade']\n",
    "    \n",
    "    return qtd_por_ano, qtd_por_mes, qtd_por_dia \n",
    "\n",
    "def qtd_noticia_fonte_autor(df_inteiro):\n",
    "    # Calcula a quantidade de notícias por fonte\n",
    "    qtd_por_fonte = df_inteiro['source.name'].value_counts().reset_index()\n",
    "    qtd_por_fonte.columns = ['fonte', 'quantidade']\n",
    "    \n",
    "    # Calcula a quantidade de notícias por autor\n",
    "    qtd_por_autor = df_inteiro['author'].value_counts().reset_index()\n",
    "    qtd_por_autor.columns = ['autor', 'quantidade']\n",
    "    \n",
    "    return qtd_por_fonte, qtd_por_autor\n",
    "\n",
    "def qtd_aparicao_palavras_chaves(df_inteiro, palavras_chave):  \n",
    "    # Adiciona colunas para cada palavra-chave no DataFrame\n",
    "    for palavra in palavras_chave:\n",
    "        df_inteiro[palavra] = df_inteiro['description'].str.contains(fr'\\b{palavra}\\b', case=False)\n",
    "    \n",
    "    df_inteiro['ano'] = df_inteiro['publishedAt'].dt.year\n",
    "    df_inteiro['mes'] = df_inteiro['publishedAt'].dt.month # Aproveitei aqui para deixar as colunas apenas do mês e do dia, pois serão útil na função \"qtd_aparicao_palavras_chaves\"\n",
    "    df_inteiro['dia'] = df_inteiro['publishedAt'].dt.day\n",
    "\n",
    "    # Agrupa por ano, mês e dia e conta a quantidade de aparições de cada palavra-chave\n",
    "    df_inteiro = df_inteiro.groupby(['ano', 'mes', 'dia'])[palavras_chave].sum().reset_index()\n",
    "    \n",
    "    # Cria um dataframe com as colunas 'ano', 'mes', 'dia' e a contagem de cada palavra-chave\n",
    "    df_contagem_palavras_chave = df_inteiro.melt(id_vars=['ano', 'mes', 'dia'], var_name='palavra_chave', value_name='quantidade')\n",
    "    \n",
    "    return df_contagem_palavras_chave   \n",
    "\n",
    "def armazenar_dados_estatisticos(qtd_por_ano, qtd_por_mes, qtd_por_dia, qtd_por_fonte, qtd_por_autor, df_contagem_palavras_chave):\n",
    "    print(\"Quantidade de notícias por ano:\")\n",
    "    print(qtd_por_ano)\n",
    "\n",
    "    print(\"\\nQuantidade de notícias por mês:\")\n",
    "    print(qtd_por_mes)\n",
    "\n",
    "    print(\"\\nQuantidade de notícias por dia:\")\n",
    "    print(qtd_por_dia)\n",
    "\n",
    "    print(\"\\nQuantidade de notícias por fonte:\")\n",
    "    print(qtd_por_fonte)\n",
    "\n",
    "    print(\"\\nQuantidade de notícias por autor:\")\n",
    "    print(qtd_por_autor)\n",
    "\n",
    "    print(\"\\nContagem de aparições das palavras-chave:\")\n",
    "    print(df_contagem_palavras_chave)\n",
    "    \n",
    "    estatisticas = pd.concat([qtd_por_ano, qtd_por_mes, qtd_por_dia, qtd_por_fonte, qtd_por_autor, df_contagem_palavras_chave], axis=1)\n",
    "    estatisticas.to_csv('resultado_final.csv', index = False)\n",
    "    #estatisticas.to_excel('resultado_final.xlsx', index = False)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chaves retornadas: dict_keys(['status', 'totalResults', 'articles'])\n",
      "Status: ok\n",
      "Total de resultados: 9\n",
      "Exemplo de artigo: {'source': {'id': None, 'name': 'Terra.com.br'}, 'author': 'Saúde em Dia', 'title': 'Cura do Alzheimer? Entenda descoberta de cientistas do Reino Unido', 'description': 'Pesquisadores do Reino Unido bloquearam ação de gene associado ao Alzheimer, impedindo progressão da doença', 'url': 'https://www.terra.com.br/vida-e-estilo/saude/cura-do-alzheimer-entenda-descoberta-de-cientistas-do-reino-unido,a5ee40a9809b64f19d78749e2171f2b4po9hhrrj.html', 'urlToImage': 'https://p2.trrsf.com/image/fget/cf/1200/630/middle/images.terra.com/2023/10/02/152503275-cura-alzheimer.jpg', 'publishedAt': '2023-10-02T11:01:16Z', 'content': \"O Alzheimer é uma enfermidade neurodegenerativa que atinge 50 milhões de pessoas em todo o mundo, indicam dados da Alzheimer's Disease International (ADI). Atualmente, apesar dos tratamentos que prop… [+3047 chars]\"}\n"
     ]
    }
   ],
   "source": [
    "# Instanciar objeto\n",
    "response = fazer_a_request_1()\n",
    "# Exibir chaves do dicionário\n",
    "print(f'Chaves retornadas: {response.keys()}')\n",
    "# Valores do dicionário\n",
    "print(f\"Status: {response['status']}\")\n",
    "print(f\"Total de resultados: {response['totalResults']}\")\n",
    "print(f\"Exemplo de artigo: {response['articles'][0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>url</th>\n",
       "      <th>urlToImage</th>\n",
       "      <th>publishedAt</th>\n",
       "      <th>content</th>\n",
       "      <th>source.id</th>\n",
       "      <th>source.name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Saúde em Dia</td>\n",
       "      <td>Cura do Alzheimer? Entenda descoberta de cient...</td>\n",
       "      <td>Pesquisadores do Reino Unido bloquearam ação d...</td>\n",
       "      <td>https://www.terra.com.br/vida-e-estilo/saude/c...</td>\n",
       "      <td>https://p2.trrsf.com/image/fget/cf/1200/630/mi...</td>\n",
       "      <td>2023-10-02 11:01:16</td>\n",
       "      <td>O Alzheimer é uma enfermidade neurodegenerativ...</td>\n",
       "      <td>desconhecido</td>\n",
       "      <td>Terra.com.br</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bethânia Nunes</td>\n",
       "      <td>IA: entenda como ela pode ser usada em benefíc...</td>\n",
       "      <td>A inteligência artificial (IA) já está present...</td>\n",
       "      <td>https://www.metropoles.com/saude/inteligencia-...</td>\n",
       "      <td>https://uploads.metropoles.com/wp-content/uplo...</td>\n",
       "      <td>2023-09-30 05:02:28</td>\n",
       "      <td>A inteligência artificial (IA) vem provocando ...</td>\n",
       "      <td>desconhecido</td>\n",
       "      <td>Metropoles.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>desconhecido</td>\n",
       "      <td>O que faz um hospital ser o melhor em oncologia</td>\n",
       "      <td>Cuidado personalizado a partir de análise de d...</td>\n",
       "      <td>https://valor.globo.com/conteudo-de-marca/hosp...</td>\n",
       "      <td>https://s2-valor.glbimg.com/RPFoLzRjiA_cCtfp4-...</td>\n",
       "      <td>2023-09-29 10:01:02</td>\n",
       "      <td>Com o crescimento no número de novos casos, qu...</td>\n",
       "      <td>globo</td>\n",
       "      <td>Globo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>desconhecido</td>\n",
       "      <td>Oncologia D’Or é referência em diagnóstico e t...</td>\n",
       "      <td>Tecnologias exclusivas, pesquisa clínica e atu...</td>\n",
       "      <td>https://valor.globo.com/patrocinado/rede-dor/n...</td>\n",
       "      <td>https://s2-valor.glbimg.com/PYwkEuo8D2pLj2KOdj...</td>\n",
       "      <td>2023-09-25 16:33:01</td>\n",
       "      <td>Todo mês, mais de dez mil pessoas buscam atend...</td>\n",
       "      <td>globo</td>\n",
       "      <td>Globo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Estadão Conteúdo</td>\n",
       "      <td>Oncologia D'Or tem protagonismo no tratamento ...</td>\n",
       "      <td>Tecnologias exclusivas, pesquisa clínica e atu...</td>\n",
       "      <td>https://www.terra.com.br/vida-e-estilo/saude/o...</td>\n",
       "      <td>https://p2.trrsf.com/image/fget/cf/1200/630/mi...</td>\n",
       "      <td>2023-09-23 03:11:18</td>\n",
       "      <td>Todo mês, mais de 10 mil pessoas buscam atendi...</td>\n",
       "      <td>desconhecido</td>\n",
       "      <td>Terra.com.br</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>desconhecido</td>\n",
       "      <td>desconhecido</td>\n",
       "      <td>Estratégia foca solicitação de exames específi...</td>\n",
       "      <td>https://www1.folha.uol.com.br/equilibrioesaude...</td>\n",
       "      <td>https://f.i.uol.com.br/fotografia/2022/02/14/1...</td>\n",
       "      <td>2023-09-22 17:39:22</td>\n",
       "      <td>Uma parceria entre um hospital público referên...</td>\n",
       "      <td>desconhecido</td>\n",
       "      <td>Uol.com.br</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Samara Schwingel</td>\n",
       "      <td>Saúde do DF registra 1,4 mil novos casos de Co...</td>\n",
       "      <td>Taxa de transmissão da Covid-19 está em 1,23 n...</td>\n",
       "      <td>https://www.metropoles.com/distrito-federal/df...</td>\n",
       "      <td>https://uploads.metropoles.com/wp-content/uplo...</td>\n",
       "      <td>2023-09-19 21:44:10</td>\n",
       "      <td>Em uma semana, o Distrito Federal registrou ma...</td>\n",
       "      <td>desconhecido</td>\n",
       "      <td>Metropoles.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Redação</td>\n",
       "      <td>Genética acessível: Exame de DNA deve ser feit...</td>\n",
       "      <td>Conheceu alguém que fez um teste genético por ...</td>\n",
       "      <td>https://claudia.abril.com.br/saude/genetica-ac...</td>\n",
       "      <td>https://claudia.abril.com.br/wp-content/upload...</td>\n",
       "      <td>2023-09-14 15:05:17</td>\n",
       "      <td>Basta raspar um cotonete por dentro da bochech...</td>\n",
       "      <td>desconhecido</td>\n",
       "      <td>Abril.com.br</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Redação</td>\n",
       "      <td>Este hábito comum pode duplicar o risco de doe...</td>\n",
       "      <td>Todos sabem que o hábito de fumar pode causar ...</td>\n",
       "      <td>https://catracalivre.com.br/saude-bem-estar/es...</td>\n",
       "      <td>https://catracalivre.com.br/cdn-cgi/image/f=au...</td>\n",
       "      <td>2023-09-13 04:00:01</td>\n",
       "      <td>Todos sabem que o hábito de fumar pode causar ...</td>\n",
       "      <td>desconhecido</td>\n",
       "      <td>Catracalivre.com.br</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             author                                              title  \\\n",
       "0      Saúde em Dia  Cura do Alzheimer? Entenda descoberta de cient...   \n",
       "1    Bethânia Nunes  IA: entenda como ela pode ser usada em benefíc...   \n",
       "2      desconhecido    O que faz um hospital ser o melhor em oncologia   \n",
       "3      desconhecido  Oncologia D’Or é referência em diagnóstico e t...   \n",
       "4  Estadão Conteúdo  Oncologia D'Or tem protagonismo no tratamento ...   \n",
       "5      desconhecido                                       desconhecido   \n",
       "6  Samara Schwingel  Saúde do DF registra 1,4 mil novos casos de Co...   \n",
       "7           Redação  Genética acessível: Exame de DNA deve ser feit...   \n",
       "8           Redação  Este hábito comum pode duplicar o risco de doe...   \n",
       "\n",
       "                                         description  \\\n",
       "0  Pesquisadores do Reino Unido bloquearam ação d...   \n",
       "1  A inteligência artificial (IA) já está present...   \n",
       "2  Cuidado personalizado a partir de análise de d...   \n",
       "3  Tecnologias exclusivas, pesquisa clínica e atu...   \n",
       "4  Tecnologias exclusivas, pesquisa clínica e atu...   \n",
       "5  Estratégia foca solicitação de exames específi...   \n",
       "6  Taxa de transmissão da Covid-19 está em 1,23 n...   \n",
       "7  Conheceu alguém que fez um teste genético por ...   \n",
       "8  Todos sabem que o hábito de fumar pode causar ...   \n",
       "\n",
       "                                                 url  \\\n",
       "0  https://www.terra.com.br/vida-e-estilo/saude/c...   \n",
       "1  https://www.metropoles.com/saude/inteligencia-...   \n",
       "2  https://valor.globo.com/conteudo-de-marca/hosp...   \n",
       "3  https://valor.globo.com/patrocinado/rede-dor/n...   \n",
       "4  https://www.terra.com.br/vida-e-estilo/saude/o...   \n",
       "5  https://www1.folha.uol.com.br/equilibrioesaude...   \n",
       "6  https://www.metropoles.com/distrito-federal/df...   \n",
       "7  https://claudia.abril.com.br/saude/genetica-ac...   \n",
       "8  https://catracalivre.com.br/saude-bem-estar/es...   \n",
       "\n",
       "                                          urlToImage         publishedAt  \\\n",
       "0  https://p2.trrsf.com/image/fget/cf/1200/630/mi... 2023-10-02 11:01:16   \n",
       "1  https://uploads.metropoles.com/wp-content/uplo... 2023-09-30 05:02:28   \n",
       "2  https://s2-valor.glbimg.com/RPFoLzRjiA_cCtfp4-... 2023-09-29 10:01:02   \n",
       "3  https://s2-valor.glbimg.com/PYwkEuo8D2pLj2KOdj... 2023-09-25 16:33:01   \n",
       "4  https://p2.trrsf.com/image/fget/cf/1200/630/mi... 2023-09-23 03:11:18   \n",
       "5  https://f.i.uol.com.br/fotografia/2022/02/14/1... 2023-09-22 17:39:22   \n",
       "6  https://uploads.metropoles.com/wp-content/uplo... 2023-09-19 21:44:10   \n",
       "7  https://claudia.abril.com.br/wp-content/upload... 2023-09-14 15:05:17   \n",
       "8  https://catracalivre.com.br/cdn-cgi/image/f=au... 2023-09-13 04:00:01   \n",
       "\n",
       "                                             content     source.id  \\\n",
       "0  O Alzheimer é uma enfermidade neurodegenerativ...  desconhecido   \n",
       "1  A inteligência artificial (IA) vem provocando ...  desconhecido   \n",
       "2  Com o crescimento no número de novos casos, qu...         globo   \n",
       "3  Todo mês, mais de dez mil pessoas buscam atend...         globo   \n",
       "4  Todo mês, mais de 10 mil pessoas buscam atendi...  desconhecido   \n",
       "5  Uma parceria entre um hospital público referên...  desconhecido   \n",
       "6  Em uma semana, o Distrito Federal registrou ma...  desconhecido   \n",
       "7  Basta raspar um cotonete por dentro da bochech...  desconhecido   \n",
       "8  Todos sabem que o hábito de fumar pode causar ...  desconhecido   \n",
       "\n",
       "           source.name  \n",
       "0         Terra.com.br  \n",
       "1       Metropoles.com  \n",
       "2                Globo  \n",
       "3                Globo  \n",
       "4         Terra.com.br  \n",
       "5           Uol.com.br  \n",
       "6       Metropoles.com  \n",
       "7         Abril.com.br  \n",
       "8  Catracalivre.com.br  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prova real que ambos os metodos de request dão o mesmo resultado\n",
    "print(fazer_a_request_1() == fazer_a_request_2())\n",
    "# teste do tratamento de dados\n",
    "df = tratar_dados(response)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Algoritmo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from newsapi import NewsApiClient\n",
    "import requests\n",
    "import time\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "API_KEY = '9a77398581d74beebbd29dbebd159a53'\n",
    "PALAVRAS_CHAVES_GERAIS = '(genômica OR genômico) AND (terapia OR sequenciamento OR doença)'\n",
    "PALAVRAS_CHAVES_ESPECIFICAS = ['terapia', 'sequenciamento', 'doença']\n",
    "\n",
    "INTERVALO = 3600 # 3600 segundos = 1 hora\n",
    "i = 0\n",
    "while True:\n",
    "\n",
    "    # 1. Consumo de dados com a News API\n",
    "    response = fazer_a_request_1(API_KEY, PALAVRAS_CHAVES_GERAIS)\n",
    "\n",
    "    # 2. Definir Critérios de Relevância\n",
    "    df_agora = tratar_dados(response)\n",
    "\n",
    "    # 3. Cargas em Batches:\n",
    "    armazenar_noticias(df_agora)\n",
    "    \n",
    "    # 4. Dados transformados para consulta do público final\n",
    "    if i==23: # i=23 referente as 24h do dia\n",
    "        df_inteiro = carrega_armazenamento()\n",
    "        df_inteiro[\"publishedAt\"] = pd.to_datetime(df_inteiro[\"publishedAt\"])\n",
    "        a, b, c = qtd_noticia_ano_mes_dia(df_inteiro)\n",
    "        d, e = qtd_noticia_fonte_autor(df_inteiro)\n",
    "        f = qtd_aparicao_palavras_chaves(df_inteiro, PALAVRAS_CHAVES_ESPECIFICAS)\n",
    "        armazenar_dados_estatisticos(a , b , c, d, e, f)\n",
    "        i = 0\n",
    "        \n",
    "    else:\n",
    "        i += 1\n",
    "        \n",
    "    time.sleep(INTERVALO)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyspark-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
